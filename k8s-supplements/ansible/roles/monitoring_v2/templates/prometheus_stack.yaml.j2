## Labels to apply to all resources
##
{% if monitoring_common_labels %}
commonLabels:
{% for label_key, label_value in monitoring_common_labels.items() %}
  {{ label_key | to_json }}: {{ label_value | to_json }}
{% endfor %}
{% endif %}

priorityClassName: "system-cluster-critical"

##
defaultRules:
  create: true
  rules:
    etcd: false # disabled for now
    kubeApiserver: false # https://github.com/prometheus-community/helm-charts/issues/1283

##
global:
  rbac:
    create: true

##
alertmanager:
  enabled: true
  alertmanagerSpec:
    priorityClassName: "system-cluster-critical"
    replicas: "{{ monitoring_alertmanager_replicas }}"
{% if monitoring_allow_external_rules %}
    alertmanagerConfigMatcherStrategy:
      type: None
{% endif %}
  serviceMonitor:
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace
  affinity: {{ lookup('template', 'roles/config/common_defaults_v1/templates/affinity.json') | to_json }}
  tolerations: {{ lookup('template', 'roles/config/common_defaults_v1/templates/tolerations.json') | to_json }}

##
grafana:
  priorityClassName: "system-cluster-critical"
  enabled: {{ monitoring_use_grafana | bool }}
  persistence:
    enabled: {{ monitoring_grafana_persistent_storage_class | ternary(true,false) }}
    storageClassName: "{{ monitoring_grafana_persistent_storage_class }}"
  admin:
    existingSecret: {{ monitoring_grafana_admin_secret_name }}
    userKey: admin-user
    passwordKey: admin-password
  resources:
    limits:
      cpu: "{{ monitoring_grafana_cpu_limit }}"
      memory: "{{ monitoring_grafana_memory_limit }}"
    requests:
      cpu: "{{ monitoring_grafana_cpu_limit }}"
      memory: "{{ monitoring_grafana_memory_request }}"
  tolerations: {{ lookup('template', 'roles/config/common_defaults_v1/templates/tolerations.json') | to_json }}
{% if monitoring_grafana_persistent_storage_class | length > 0 %}
  affinity: {{ lookup('template', 'roles/config/common_defaults_v1/templates/affinity.json', template_vars=dict(pod_affinity_key="app.kubernetes.io/name", pod_affinity_operator="In", pod_affinity_values=["grafana"])) | to_json }}
{% else %}
  affinity: {{ lookup('template', 'roles/config/common_defaults_v1/templates/affinity.json') | to_json }}
{% endif %}
  datasources:
    datasources.yaml:
      apiVersion: 1
{% if monitoring_use_thanos %}
      datasources:
        - name: thanos
          type: prometheus
          access: proxy
          orgId: 1
          url: "http://thanos-query.{{ monitoring_namespace }}.svc:9090"
          version: 1
          editable: false
{% endif %}
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      searchNamespace: "ALL"
      folderAnnotation: customer-dashboards
      provider:
        foldersFromFilesStructure: true
{% if monitoring_grafana_dashboard_enable_multicluster_support | bool %}
      multicluster:
        global:
          enabled: true
{% endif %}
  serviceMonitor:
    enabled: true
{% if monitoring_common_labels %}
    labels:
{% for label_key, label_value in monitoring_common_labels.items() %}
      {{ label_key | to_json }}: {{ label_value | to_json }}
{% endfor %}
{% endif %}
    # https://github.com/prometheus-community/helm-charts/issues/1776
    interval: "30s"
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace
  dashboards:
    managed:
      dashboard-calico:
        gnetId: 12175
        revision: 5
        datasource: Prometheus
{% if k8s_storage_rook_enabled %}
      dashboard-ceph-cluster:
        gnetId: 2842
        revision: 14
        datasource: Prometheus
      dashboard-ceph-osd-single:
        gnetId: 5336
        revision: 5
        datasource: Prometheus
      dashboard-ceph-pools:
        gnetId: 5342
        revision: 5
        datasource: Prometheus
{% endif %}
{% if monitoring_use_thanos %}
      dashboard-thanos:
        gnetId: 12937
        revision: 4
        datasource: Prometheus
{% endif %}
{% if k8s_ingress_enabled | bool %}
      dashboard-nginx-ingress:
        gnetId: 9614
        revision: 1
        datasource: Prometheus
{% endif %}
  dashboardProviders:
    managed-dashboard-provider.yaml:
      apiVersion: 1
      providers:
        - name: 'managed-dashboards'
          folder: 'managed-dashboards'
          options:
            path: /var/lib/grafana/dashboards/managed
  grafana.ini:
    server:
{% if monitoring_grafana_root_url | length > 0 %}
      root_url: {{ monitoring_grafana_root_url | to_json }}
{% endif %}

##
kubeApiServer:
  enabled: true
  serviceMonitor:
    relabelings:
      - sourceLabels:
          - __meta_kubernetes_namespace
          - __meta_kubernetes_service_name
          - __meta_kubernetes_endpoint_port_name
        action: keep
        regex: default;kubernetes;https
      - targetLabel: __address__
        replacement: kubernetes.default.svc:443
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace

##
kubelet:
  enabled: true
  serviceMonitor:
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace
      - sourceLabels: [__metrics_path__]
        targetLabel: metrics_path
        action: replace

##
kubeControllerManager:
  enabled: true
  service:
    port: 10257
    targetPort: 10257
  serviceMonitor:
    enabled: true
    https: true
    insecureSkipVerify: true
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace

##
coreDNS:
  enabled: true
  serviceMonitor:
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace

##
kubeEtcd:
  enabled: true
  service:
    enabled: true
    port: 2381
    targetPort: 12381
    selector:
      app.kubernetes.io/name: etcd-proxy-metrics
  serviceMonitor:
    enabled: true
    scheme: https
    insecureSkipVerify: false
    caFile: /etc/prometheus/secrets/etcd-metrics-proxy/server.crt
    certFile: /etc/prometheus/secrets/etcd-metrics-proxy/client.crt
    keyFile: /etc/prometheus/secrets/etcd-metrics-proxy/client.key

##
kubeScheduler:
  enabled: true
  service:
    enabled: true
    port: 10259
    targetPort: 10259
  serviceMonitor:
    enabled: true
    https: true
    insecureSkipVerify: true
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace

##
kubeProxy:
  enabled: {{ (k8s_network_plugin in ['calico']) | bool }}
  serviceMonitor:
    enabled: true
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace

##
kubeStateMetrics:
  enabled: true
  serviceMonitor:
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace

##
kube-state-metrics:
  priorityClassName: "system-cluster-critical"
  rbac:
    create: true
    pspEnabled: false
{% if monitoring_common_labels %}
  customLabels:
{% for label_key, label_value in monitoring_common_labels.items() %}
    {{ label_key | to_json }}: {{ label_value | to_json }}
{% endfor %}
{% endif %}
  metricLabelsAllowlist:
    - namespaces=[*]

##
nodeExporter:
  enabled: true
  ## Use the value configured in prometheus-node-exporter.podLabels
  jobLabel: jobLabel

## Configuration for prometheus-node-exporter subchart
##
prometheus-node-exporter:
  priorityClassName: "system-node-critical"
  namespaceOverride: ""
  podLabels:
    ## Add the 'node-exporter' label to be used by serviceMonitor to match standard common usage in rules and grafana dashboards
    ##
    jobLabel: node-exporter
  extraArgs:
    - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  prometheus:
    monitor:
      enabled: true
{% if monitoring_common_labels %}
      additionalLabels:
{% for label_key, label_value in monitoring_common_labels.items() %}
        {{ label_key | to_json }}: {{ label_value | to_json }}
{% endfor %}
{% endif %}
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_node_name]
          separator: ;
          regex: ^(.*)$
          targetLabel: nodename
          replacement: $1
          action: replace

##
prometheusOperator:
  enabled: true
  priorityClassName: "system-cluster-critical"
  admissionWebhooks:
    patch:
      priorityClassName: "system-cluster-critical"
  resources:
    limits:
      cpu: {{ monitoring_prometheus_operator_cpu_limit | to_json }}
      memory: {{ monitoring_prometheus_operator_memory_limit | to_json }}
    requests:
      cpu: {{ monitoring_prometheus_operator_cpu_request | to_json }}
      memory: {{ monitoring_prometheus_operator_memory_request | to_json }}
  serviceMonitor:
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace
  affinity: {{ lookup('template', 'roles/config/common_defaults_v1/templates/affinity.json') | to_json }}
  tolerations: {{ lookup('template', 'roles/config/common_defaults_v1/templates/tolerations.json') | to_json }}

##
prometheus:
  enabled: true
  thanosService:
    enabled: {{ monitoring_use_thanos | bool }}
  thanosServiceMonitor:
    enabled: {{ monitoring_use_thanos | bool }}
  serviceMonitor:
    relabelings:
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        separator: ;
        regex: ^(.*)$
        targetLabel: nodename
        replacement: $1
        action: replace
  prometheusSpec:
    priorityClassName: "system-cluster-critical"
{% if monitoring_remote_writes | length > 0 %}
    remoteWrite:
{% for remote_write in monitoring_remote_writes %}
      - url: {{ remote_write.url | to_json }}
        writeRelabelConfigs: {{ remote_write.write_relabel_configs | to_json }}
{% endfor %}
{% endif %}
    secrets:
      - etcd-metrics-proxy
    serviceMonitorSelectorNilUsesHelmValues: {{  monitoring_common_labels | ternary(true, false) }}
{% if monitoring_prometheus_persistent_storage_class %}
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: {{ monitoring_prometheus_persistent_storage_class | to_json }}
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: {{ monitoring_prometheus_persistent_storage_resource_request | to_json }}
{% endif %}
{% if monitoring_common_labels %}
    serviceMonitorSelector:
      matchLabels:
{% for label_key, label_value in monitoring_common_labels.items() %}
        {{ label_key | to_json }}: {{ label_value | to_json }}
{% endfor %}
{% endif %}
{% if monitoring_use_thanos | bool %}
    thanos:
      objectStorageConfig:
        optional: false
{% if monitoring_prometheus_stack_version is version('51.0.0', '>=') %}
        existingSecret:
          name: thanos-sidecar-bucket-credentials-config
          key: thanos.yaml
{% else %}
        name: thanos-sidecar-bucket-credentials-config
        key: thanos.yaml
{% endif %}
{% endif %}
    containers:
      - name: prometheus
        readinessProbe:
          failureThreshold: 1000
    resources:
      requests:
        cpu: "{{ monitoring_prometheus_cpu_request }}"
        memory: "{{ monitoring_prometheus_memory_request }}"
      limits:
        cpu: "{{ monitoring_prometheus_cpu_limit }}"
        memory: "{{ monitoring_prometheus_memory_limit }}"
    affinity: {{ lookup('template', 'roles/config/common_defaults_v1/templates/affinity.json') | to_json }}
    tolerations: {{ lookup('template', 'roles/config/common_defaults_v1/templates/tolerations.json') | to_json }}
{% if monitoring_allow_external_rules %}
    ruleSelectorNilUsesHelmValues: false
    ruleSelector: {}
    ruleNamespaceSelector: {}
{% endif %}
