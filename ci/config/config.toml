[terraform]
subnet_cidr = "172.30.154.0/24"
haproxy_ports = [30060]
workers = 6
default_master_image_name = "mk8s-ci-ubuntu-1804-nightly"
default_worker_image_name = "mk8s-ci-ubuntu-1804-nightly"
gateway_image_name = "mk8s-ci-debian-10-nightly"
worker_flavors = ["L", "M", "L", "M", "L", "M"]
enable_az_management = false

# dd2a only
#azs = ["nova"]
#public_network = "floating-IPv4"

[ansible.02_trampoline.group_vars.gateways]
# Variable is repeated because its other definition is not visible here.
deprecated_nodeport_lb_test_port = 30060
lb_ports = ["{{ deprecated_nodeport_lb_test_port }}"]
wg_ip_cidr = "172.30.153.0/24"
wg_ip_gw = "172.30.153.1/24"

[[ansible.02_trampoline.group_vars.gateways.wg_peers]]
pub_key = "/0VYI+LK2VYUX3E7QDUCfp7p+0vU2tocsqGFjsKoJVs="
ip = "172.30.153.14/32"
ident = "gitlab-ci-runner"

[ansible.02_trampoline.host_vars.managed-k8s-gw-az1]
vrrp_priority = 150

[ansible.02_trampoline.host_vars.managed-k8s-gw-az2]
vrrp_priority = 100

[ansible.02_trampoline.host_vars.managed-k8s-gw-az3]
vrrp_priority = 50

[ansible.03_final.host_vars.managed-k8s-gw-az1]
vrrp_priority = 150

[ansible.03_final.host_vars.managed-k8s-gw-az2]
vrrp_priority = 100

[ansible.03_final.host_vars.managed-k8s-gw-az3]
vrrp_priority = 50

[ansible.03_final.group_vars.all]
ch_k8s_lbaas = true
ch_k8s_lbaas_version = "0.3.3"
ch_k8s_lbaas_shared_secret = "IYeOlEFO1h3uc9x1bdw9thNNgmn1gm8dmzos3f04PLmFjt3d"
lb_ports = [30080]
k8s_version = "1.18.18"
rook = true
rook_nosds = 3
rook_osd_volume_size = "90Gi"
rook_toolbox = true
rook_fs = true
rook_mon_volume = true
rook_mon_volume_storage_class = "local-storage"

k8s_use_podsecuritypolicies = true
k8s_network_plugin = "kube-router"
monitoring_thanos_objectstorage_container_name = "managed-k8s-monitoring-thanos-data"

rook_placement_label = { key = "{{ managed_k8s_control_plane_key }}", value = "storage" }

rook_placement_taint = { key = "{{ managed_k8s_control_plane_key }}", value = "storage" }

monitoring_placement_label = { key = "{{ managed_k8s_control_plane_key }}", value = "monitoring" }

# To prevent the CI running in CPU limits here and failing because of that
rook_mon_cpu_limit = "500m"
rook_mon_cpu_request = "100m"
rook_operator_cpu_limit = "500m"
rook_operator_cpu_request = "100m"

monitoring_prometheus_memory_limit = "1Gi"
monitoring_prometheus_cpu_limit = "200m"

# Variable is repeated because its other definition is not visible here.
deprecated_nodeport_lb_test_port = 30060

[[ansible.03_final.group_vars.all.test_worker_nodes]]
worker = "managed-k8s-worker-1"
name = "worker0"

[[ansible.03_final.group_vars.all.test_worker_nodes]]
worker = "managed-k8s-worker-3"
name = "worker1"

[[ansible.03_final.group_vars.all.test_worker_nodes]]
worker = "managed-k8s-worker-5"
name = "worker2"

[ansible.03_final.host_vars.managed-k8s-worker-0]
k8s_node_labels = [ "{{ managed_k8s_control_plane_key }}=storage" ]
k8s_node_taints = [ "{{ managed_k8s_control_plane_key }}=storage:NoSchedule",]

[ansible.03_final.host_vars.managed-k8s-worker-1]
k8s_node_labels = [ "{{ managed_k8s_control_plane_key }}=monitoring" ]

[ansible.03_final.host_vars.managed-k8s-worker-2]
k8s_node_labels = [ "{{ managed_k8s_control_plane_key }}=storage" ]
k8s_node_taints = [ "{{ managed_k8s_control_plane_key }}=storage:NoSchedule",]

[ansible.03_final.host_vars.managed-k8s-worker-3]
k8s_node_labels = [ "{{ managed_k8s_control_plane_key }}=monitoring" ]

[ansible.03_final.host_vars.managed-k8s-worker-4]
k8s_node_labels = [ "{{ managed_k8s_control_plane_key }}=storage" ]
k8s_node_taints = [ "{{ managed_k8s_control_plane_key }}=storage:NoSchedule",]

[ansible.03_final.host_vars.managed-k8s-worker-5]
k8s_node_labels = [ "{{ managed_k8s_control_plane_key }}=monitoring" ]

[secrets]
passwordstore_rollout_company_users = false # False because we don't have the keys
[[secrets.passwordstore_additional_users]]
ident = "mk8s-ci@gitlab"
gpg_id = "mk8s-ci@gitlab"
