# A GPU has been detected
# Prerequisits: enable IOMMU
---
- name: Install GPU drivers
  become: true
  when:
    - k8s_virtualize_gpu | default(False)
    - has_gpu
    - _allow_disruption or install_status == 'k8s_not_installed'
    - ansible_facts['pkg_mgr'] == "apt"
  block:
    - name: Get CPU information  # noqa no-changed-when
      ansible.builtin.command: lscpu
      register: cpu_info

    - name: look into CPU information
      when: '"Intel" is in cpu_info.stdout'
      ansible.builtin.set_fact:
        cpu_type: "intel"

    - name: look into CPU information
      when: '"AMD" is in cpu_info.stdout'
      ansible.builtin.set_fact:
        cpu_type: "amd"

    - name: Enable IOMMU
      ansible.builtin.copy:
        dest: /etc/default/grub.d/enable_iommu.cfg
        content: |
          GRUB_CMDLINE_LINUX="{{ cpu_type }}_iommu=on iommu=pt .modeset=0 rd.driver.pre=vfio-pci video=vesafb:off"
        owner: root
        group: root
        mode: 0644
      register: grub_config

    - name: Update GRUB
      when: grub_config.changed
      ansible.builtin.command: update-grub

    - name: Install deps for the nvidia drivers
      ansible.builtin.apt:
        state: present
        name:
          - "linux-headers-{{ ansible_kernel }}"
          - build-essential
          - manpages-dev
      register: task_result
      until: task_result is not failed
      retries: "{{ network_error_retries }}"
      delay: "{{ network_error_delay }}"


    - name: Install virtual gpu manager
      block:
        - name: Download the nvidia vgpu driver script on the host
          ansible.builtin.get_url:
            url: "{{ nvidia_vgpu_driver_blob_url }}/{{ nvidia_vgpu_manager_filename }}"
            dest: "/tmp/{{ nvidia_vgpu_manager_filename }}"
            mode: '0755'
          register: task_result
          until: task_result is not failed
          retries: "{{ network_error_retries }}"
          delay: "{{ network_error_delay }}"

        - name: Install the virtual gpu manager
          ansible.builtin.apt:
            deb: '/tmp/{{ nvidia_vgpu_manager_filename }}'
          register: installed_vgpu_manager
          until: installed_vgpu_manager is not failed
          retries: "{{ network_error_retries }}"
          delay: "{{ network_error_delay }}"

    - name: Blacklist nouveau
      # The installation script lies! It says: """
      # update-initramfs: deferring update (trigger activated)
      # A modprobe blacklist file has been created at /etc/modprobe.d to prevent Nouveau
      # from loading. This can be reverted by deleting the following file:
      # /etc/modprobe.d/nvidia-graphics-drivers.conf"""
      # And guess what? That configuration file doesn't exist!
      ansible.builtin.copy:
        dest: /etc/modprobe.d/blacklist_nouveau.conf
        content: |
          {{ _auto_generated_preamble }}
          blacklist nouveau
          options nouveau modeset=0
        mode: 0755
        owner: root
        group: root
      register: blacklisted_nouveau

    - name: Update initramfs
      ansible.builtin.command: "update-initramfs -k {{ ansible_kernel }} -uv"
      when: blacklisted_nouveau.changed or installed_vgpu_manager.changed
      register: ramfs

    - name: Reboot block
      become: true
      when: ramfs is changed or grub_config is changed
      block:

        - name: Reboot the system (cloud-init run)
          ansible.builtin.command:
            argv:
              - reboot
              - now
          when: ansible_connection == 'local'

        # We do not need a "when" here. ansible is killed approximately immediately
        # anyway by the above command if it is executed; If the above command is
        # not executed, we want to execute this one.
        - name: Reboot the system
          ansible.builtin.reboot:

    - name: Basic sanity check with nvidia-smi
      # nvidia-smi -L lists all detected cards.
      # I installed the toolchain on a host with any nvidia cards and the rc was != 0.
      # It's therefore safe to assume that if the installation somehow failed, then this task would fail too.
      changed_when: false
      ansible.builtin.command: nvidia-smi -L

    - name: Ensure group "libvirt" exists with correct gid
      ansible.builtin.group:
        name: libvirt
        state: present
        gid: 2500009

    - name: Create udev rule for vfio devices
      become: true
      ansible.builtin.template:
        src: 50-vfio.rules.j2
        dest: /etc/udev/rules.d/50-vfio.rules
        owner: root
        group: root
        mode: 0644
      register: udev_vfio_rule

    - name: Reload udev rules on the node
      # nvidia-smi -L lists all detected cards.
      # I installed the toolchain on a host with any nvidia cards and the rc was != 0.
      # It's therefore safe to assume that if the installation somehow failed, then this task would fail too.
      when: udev_vfio_rule.changed
      ansible.builtin.command: "{{ item }}"
      with_items:
        - udevadm control --reload-rules
        - udevadm trigger

    - name: run sriov-manage once to create VFs  # noqa no-changed-when
      # executing the variant of the reboot systemd service during installation does not work properly we
      # rather run the command once after installation and just enable the systemd service to run for consecutive reboots
      ansible.builtin.command: "/usr/lib/nvidia/sriov-manage -e ALL"

    - name: install nvidia-sriov-manage systemd unit file
      ansible.builtin.template:
        src: nvidia-sriov-manage.service.j2
        dest: /etc/systemd/system/nvidia-sriov-manage.service
        owner: root
        group: root
        mode: 0644

    - name: create sriov-loop script (used by nvidia-sriov-manage systemd unit)
      ansible.builtin.template:
        src: nvidia-sriov-startup-loop.sh.j2
        dest: /usr/local/bin/nvidia-sriov-startup-loop.sh
        owner: root
        group: root
        mode: 0744

    - name: enable nvidia-sriov-manage
      ansible.builtin.systemd:
        enabled: true
        name: nvidia-sriov-manage.service
        daemon_reload: true
...
