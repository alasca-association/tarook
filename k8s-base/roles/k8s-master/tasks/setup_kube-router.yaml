---
- name: Detect presence of flannel
  become: yes
  stat:
    path: /etc/cni/net.d/10-flannel.conflist
  register: flannel_conf

- name: Fail if flannel config exists and disruption is not allowed
  when:
  - flannel_conf.stat.exists
  - not _allow_disruption
  fail:
    msg: |
      Flannel configuration found, but going to install kube-router.
      This requires restart of all pods, which may lose data.
      Disruptions were not allowed, so bailing out.

- name: Fail if restart mode is not configured
  when:
  - flannel_conf.stat.exists
  - not k8s_network_plugin_switch_restart_all_namespaces is defined
  fail:
    msg: |
      Flannel configuration found, but going to install kube-router.
      That means that all Pods need restarting. You need to pick whether
      ansible shall automatically restart all Deployments, DaemonSets and
      StatefulSets in (1) all namespaces or (2) only in some namespaces.
      Please set k8s_network_plugin_switch_restart_all_namespaces and
      k8s_network_plugin_switch_restart_namespaces accordingly.

- import_tasks: remove_flannel.yaml
- import_tasks: remove_kube-proxy.yaml

- name: Setup kube-router
  become: yes
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  k8s:
    definition: "{{ lookup('template', 'kubeadm-kuberouter.yaml') }}"
    apply: yes
    state: "present"
    validate:
      fail_on_error: yes
      strict: yes

- name: Enumerate all nodes
  become: yes
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  k8s_info:
    api_version: v1
    kind: Node
  register: nodes

- name: Wait for kube-router to be up on all nodes
  become: yes
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  k8s_info:
    api_version: apps/v1
    kind: DaemonSet
    namespace: kube-system
    name: kube-router
  register: kube_router_ds
  until: |
    ((kube_router_ds.resources | default(False)) and
     (kube_router_ds.resources[0].status | default(False)) and
     (kube_router_ds.resources[0].status.numberReady == nodes.resources | length) and
     (kube_router_ds.resources[0].status.numberAvailable == nodes.resources | length))
  retries: 60
  delay: 3

- name: Restart ALL THE THINGS if flannel existed
  vars:
    object_classes:
    - api_version: apps/v1
      kind: DaemonSet
    - api_version: apps/v1
      kind: Deployment
    - api_version: apps/v1
      kind: StatefulSet
  run_once: yes
  become: yes
  when: flannel_conf.stat.exists
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf

  block:
  - name: Find all namespaces
    k8s_info:
      api_version: v1
      kind: Namespace
    register: namespaces
    when: k8s_network_plugin_switch_restart_all_namespaces

  - name: Find all the deployments, daemonsets, and statefulsets
    k8s_info:
      api_version: "{{ item[1].api_version }}"
      namespace: "{{ (item[0] is string) | ternary(item[0], item[0].metadata.name) }}"
      kind: "{{ item[1].kind }}"
    register: objects
    loop: |
      {{ flannel_conf.stat.exists | ternary(
          (namespaces is skipped) | ternary(
            k8s_network_plugin_switch_restart_namespaces,
            namespaces.resources | default([])
          ),
          []
        ) | product(object_classes) | list }}

  - name: Restart ALL THE THINGS after flannel removal
    loop: "{{ objects.results | default([]) | subelements('resources') | list }}"
    loop_control:
      label: "{{ namespace }}/{{ object_kind }}/{{ object_name }}"
    vars:
      namespace: "{{ item[1].metadata.namespace }}"
      object_kind: "{{ item[1].kind }}"
      object_name: "{{ item[1].metadata.name }}"
    command:
    args:
      argv:
      - kubectl
      - "--namespace"
      - "{{ namespace }}"
      - rollout
      - restart
      - "{{ object_kind }}"
      - "{{ object_name }}"

- name: Mark networking as configured
  set_fact:
    runtime_k8s_networking_configured: true
