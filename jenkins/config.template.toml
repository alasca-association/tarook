[ansible.02_trampoline.group_vars.gateways]
lb_ports = [
  30060
]
cah_users_include_users = ["<user>", "<user>"]

# IP address range to use for WireGuard clients. Must be set to a CIDR and must
# not conflict with the terraform.subnet_cidr.
#
# Should be chosen uniquely for all clusters of a customer at the very least
# so that they can use all of their clusters at the same time without having
# to tear down tunnels.
wg_ip_cidr = "172.30.153.64/26"
wg_ip_gw = "172.30.153.65/26"

# To add WireGuard keys for customers, create blocks like the following:
#
#[[ansible.02_trampoline.group_vars.gateways.wg_peers]]
#pub_key = "test1"
#ident = "testkunde1"
#
# You can add as many of them as you want. toml_helper.py will auto-allocate IP
# addresses from the wg_ip_cidr.

[ansible.02_trampoline.host_vars.managed-k8s-gw-az1]
vrrp_priority = 150

[ansible.02_trampoline.host_vars.managed-k8s-gw-az2]
vrrp_priority = 100

[ansible.02_trampoline.host_vars.managed-k8s-gw-az3]
vrrp_priority = 80

[ansible.03_final.group_vars.all]
k8s_version = "1.17.3"
rook = true
rook_nosds = 3
rook_osd_volume_size = "90Gi"
rook_toolbox = true
rook_fs = true
cah_users_include_users = ["<user>", "<user>"]

# To enable our LBaaS service, un-comment the following options and fill in a
# unique, random, base64-encoded secret in place of `...`.
#
# To generate such a secret, you can use the following command:
#
# $ dd if=/dev/urandom bs=16 count=1 status=none | base64
#
#ch_k8s_lbaas = true
#ch_k8s_lbaas_shared_secret = "..."
#ch_k8s_lbaas_version = "0.2.0"

# Pick a networking plugin:
#
# - kube-router: High-performance, low-overhead implementation with support
#   for NetworkPolicy objects
# - flannel: Historical default option. Do not use for new clusters. It is
#   still the default (from the ansible side) to not break existing clusters.
k8s_network_plugin = "kube-router"

# When upgrading to kube-router, configuration on how to handle the transition
# is required. Note that all pods MUST be restarted (otherwise they’ll have no
# connectivity after the restart).
#
# If set to true, ansible will restart all DaemonSets, StatefulSets and
# Deployments in all namespaces via `kubectl rollout restart`. If set to false,
# only our managed namespaces (rook-ceph, monitoring and kube-system) are
# restarted, which means that the customer will have to do their own restarts.
#k8s_network_plugin_switch_restart_all_namespaces=true
#
# This can be used to change the set of namespaces where restarts are
# automatically carried out if k8s_network_plugin_switch_restart_all_namespaces
# is set to false. Generally, you’ll not want to change this.
#
#k8s_network_plugin_switch_restart_namespaces=[...]

[ansible.03_final.host_vars.managed-k8s-gw-az1]
vrrp_priority = 150

[ansible.03_final.host_vars.managed-k8s-gw-az2]
vrrp_priority = 100

[ansible.03_final.host_vars.managed-k8s-gw-az3]
vrrp_priority = 80

[[ansible.03_final.group_vars.all.test_worker_nodes]]
worker = "managed-k8s-worker-0"
name = "worker0"

[[ansible.03_final.group_vars.all.test_worker_nodes]]
worker = "managed-k8s-worker-1"
name = "worker1"

[[ansible.03_final.group_vars.all.test_worker_nodes]]
worker = "managed-k8s-worker-2"
name = "worker2"

[terraform]
subnet_cidr = "172.30.154.0/24"
workers = 3
