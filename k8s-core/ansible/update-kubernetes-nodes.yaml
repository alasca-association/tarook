---
- name: Initialize node connection
  import_playbook: "connect-to-nodes.yaml"
  vars:
    target_hosts: k8s_nodes

- name: Fail if node got not bootstrapped once, yet
  any_errors_fatal: true
  hosts: k8s_nodes
  tasks:
  - name: Fail if node got not bootstrapped once, yet
    when: not ansible_local['bootstrap']['bootstrapped'] | default(False) | bool
    fail:
      msg: |
        ERROR

        We're at an advanced stage of the rollout,
        but the node did not get bootstrapped yet!
        Please ensure the k8s-core/bootstrap playbook
        is executed at least once against every node
        before proceeding.
        This is automatically done if the install-all
        playbook of either k8s-core or k8s-supplements is executed.

- name: Group Kubernetes nodes by initialization status
  hosts: k8s_nodes
  gather_facts: true
  tags: update-kubernetes-nodes
  tasks:
  - name: Group Kubernetes nodes by initialization status
    ansible.builtin.group_by:
      key: "{{ ansible_local['kubernetes-initialized']['k8s_install_status'] | default('not_initialized') }}_kubernetes_nodes"

- name: Upgrade initialized k8s nodes
  hosts: initialized_kubernetes_nodes
  gather_facts: true
  serial: 1
  vars_files:
  - vars/disruption.yaml
  - vars/retries.yaml
  tags: update-kubernetes-nodes
  roles:
  - role: cluster-health-verification
    delegate_to: "{{ groups['orchestrator'] | first }}"
    when:
    - not (k8s_skip_upgrade_checks | bool)
    - _allow_disruption
  - role: kubeadm-drain-node
    when: _allow_disruption
  - role: update-system
    when: _allow_disruption
  - role: kubeadm-uncordon-node
    when: _allow_disruption

- name: Upgrade uninitialized k8s nodes
  hosts: not_initialized_frontend_nodes:&not_initialized_kubernetes_nodes
  gather_facts: true
  vars_files:
  - vars/disruption.yaml
  - vars/retries.yaml
  tags: update-kubernetes-nodes
  roles:
  - role: update-system
    tags: update-system
...
